{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:05:10.465764Z",
     "end_time": "2023-08-25T15:05:22.040642Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = fetch_openml('mnist_784', version=1, parser='auto')  # data from https://www.openml.org/d/554\n",
    "dfData = pd.DataFrame(np.c_[data[\"data\"], data[\"target\"]],\n",
    "                      columns = data[\"feature_names\"] + [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:05:22.047644Z",
     "end_time": "2023-08-25T15:05:25.485150Z"
    }
   },
   "outputs": [],
   "source": [
    "stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "for train_index, test_index in stratSplit.split(dfData[data[\"feature_names\"]], dfData[\"target\"]):\n",
    "    X_train = dfData[data[\"feature_names\"]].iloc[train_index]\n",
    "    X_test = dfData[data[\"feature_names\"]].iloc[test_index]\n",
    "    \n",
    "    y_train = dfData[\"target\"].iloc[train_index]\n",
    "    y_test = dfData[\"target\"].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:05:25.490150Z",
     "end_time": "2023-08-25T15:09:11.029937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.91575           nan 0.91532143        nan 0.91560715]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.93799107        nan 0.93798214        nan 0.93819642]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.99239639        nan 0.99240437        nan 0.99240299]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.9956692         nan 0.99566703        nan 0.99568265]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.91451884        nan 0.91407424        nan 0.91436886]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.93712965        nan 0.93713557        nan 0.937348  ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}],\n             refit='roc_auc_ovr_weighted', return_train_score=True,\n             scoring=['accuracy', 'roc_auc_ovr_weighted', 'f1_macro'])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n             refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n             scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n             refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n             scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = [{\"penalty\":[\"l1\",\"l2\"],\"C\":[0.1,1,10]}]\n",
    "#         {\"penalty\":[\"elasticnet\"],\"C\":[0.1,1,10, 100],\"l1_ratio\":[0.1,0.3]}] #\"max_iter\":[100]\n",
    "\n",
    "logreg_clf_gscv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                               param_grid = params,\n",
    "                               scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                               refit = \"roc_auc_ovr_weighted\",  # True\n",
    "                               cv = 3,  # If our estimator is classifier automatically do stratified CV\n",
    "                               # n_jobs = -1,  # Num CPUs to use for calculation, -1 means all\n",
    "                               verbose = 0,  # Output status updates, higher number-> more messages\n",
    "                               return_train_score = True)  # if false our results won't contain training scores\n",
    "logreg_clf_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:11.037937Z",
     "end_time": "2023-08-25T16:13:24.275670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_penalty', 'param_solver', 'params', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_roc_auc_ovr_weighted', 'split1_test_roc_auc_ovr_weighted', 'split2_test_roc_auc_ovr_weighted', 'mean_test_roc_auc_ovr_weighted', 'std_test_roc_auc_ovr_weighted', 'rank_test_roc_auc_ovr_weighted', 'split0_train_roc_auc_ovr_weighted', 'split1_train_roc_auc_ovr_weighted', 'split2_train_roc_auc_ovr_weighted', 'mean_train_roc_auc_ovr_weighted', 'std_train_roc_auc_ovr_weighted', 'split0_test_f1_macro', 'split1_test_f1_macro', 'split2_test_f1_macro', 'mean_test_f1_macro', 'std_test_f1_macro', 'rank_test_f1_macro', 'split0_train_f1_macro', 'split1_train_f1_macro', 'split2_train_f1_macro', 'mean_train_f1_macro', 'std_train_f1_macro'])\n"
     ]
    }
   ],
   "source": [
    "print(logreg_clf_gscv.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:11.040936Z",
     "end_time": "2023-08-25T15:09:11.121936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.493883      0.015601         0.000000        0.000000     0.1   \n",
      "4       0.515670      0.013353         0.000000        0.000000      10   \n",
      "2       0.586178      0.072537         0.000000        0.000000       1   \n",
      "1      14.514792      0.282079         2.005798        0.024785     0.1   \n",
      "3      15.744413      0.133147         2.131112        0.037199       1   \n",
      "5      15.770614      0.311486         2.240880        0.114965      10   \n",
      "\n",
      "  param_penalty                       params  split0_test_accuracy  \\\n",
      "0            l1  {'C': 0.1, 'penalty': 'l1'}                   NaN   \n",
      "4            l1   {'C': 10, 'penalty': 'l1'}                   NaN   \n",
      "2            l1    {'C': 1, 'penalty': 'l1'}                   NaN   \n",
      "1            l2  {'C': 0.1, 'penalty': 'l2'}              0.917019   \n",
      "3            l2    {'C': 1, 'penalty': 'l2'}              0.916484   \n",
      "5            l2   {'C': 10, 'penalty': 'l2'}              0.916376   \n",
      "\n",
      "   split1_test_accuracy  split2_test_accuracy  ...  split1_test_f1_macro  \\\n",
      "0                   NaN                   NaN  ...                   NaN   \n",
      "4                   NaN                   NaN  ...                   NaN   \n",
      "2                   NaN                   NaN  ...                   NaN   \n",
      "1              0.914609              0.915622  ...              0.913319   \n",
      "3              0.914287              0.915193  ...              0.912973   \n",
      "5              0.914341              0.916104  ...              0.913050   \n",
      "\n",
      "   split2_test_f1_macro  mean_test_f1_macro  std_test_f1_macro  \\\n",
      "0                   NaN                 NaN                NaN   \n",
      "4                   NaN                 NaN                NaN   \n",
      "2                   NaN                 NaN                NaN   \n",
      "1              0.914265            0.914519           0.001098   \n",
      "3              0.913819            0.914074           0.001020   \n",
      "5              0.914758            0.914369           0.000958   \n",
      "\n",
      "   rank_test_f1_macro  split0_train_f1_macro  split1_train_f1_macro  \\\n",
      "0                   4                    NaN                    NaN   \n",
      "4                   4                    NaN                    NaN   \n",
      "2                   4                    NaN                    NaN   \n",
      "1                   1               0.937429               0.936461   \n",
      "3                   3               0.937415               0.937111   \n",
      "5                   2               0.937361               0.936946   \n",
      "\n",
      "   split2_train_f1_macro  mean_train_f1_macro  std_train_f1_macro  \n",
      "0                    NaN                  NaN                 NaN  \n",
      "4                    NaN                  NaN                 NaN  \n",
      "2                    NaN                  NaN                 NaN  \n",
      "1               0.937499             0.937130            0.000474  \n",
      "3               0.936881             0.937136            0.000219  \n",
      "5               0.937737             0.937348            0.000323  \n",
      "\n",
      "[6 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "resultsCVDF = pd.DataFrame(logreg_clf_gscv.cv_results_)\n",
    "print(resultsCVDF.sort_values(\"mean_fit_time\",ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:11.128936Z",
     "end_time": "2023-08-25T15:09:11.139937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "mean_fit_time                                        15.744413\nstd_fit_time                                          0.133147\nmean_score_time                                       2.131112\nstd_score_time                                        0.037199\nparam_C                                                      1\nparam_penalty                                               l2\nparams                               {'C': 1, 'penalty': 'l2'}\nsplit0_test_accuracy                                  0.916484\nsplit1_test_accuracy                                  0.914287\nsplit2_test_accuracy                                  0.915193\nmean_test_accuracy                                    0.915321\nstd_test_accuracy                                     0.000901\nrank_test_accuracy                                           3\nsplit0_train_accuracy                                 0.938285\nsplit1_train_accuracy                                  0.93791\nsplit2_train_accuracy                                 0.937751\nmean_train_accuracy                                   0.937982\nstd_train_accuracy                                    0.000224\nsplit0_test_roc_auc_ovr_weighted                      0.992189\nsplit1_test_roc_auc_ovr_weighted                      0.992319\nsplit2_test_roc_auc_ovr_weighted                      0.992705\nmean_test_roc_auc_ovr_weighted                        0.992404\nstd_test_roc_auc_ovr_weighted                         0.000219\nrank_test_roc_auc_ovr_weighted                               1\nsplit0_train_roc_auc_ovr_weighted                     0.995648\nsplit1_train_roc_auc_ovr_weighted                     0.995753\nsplit2_train_roc_auc_ovr_weighted                     0.995601\nmean_train_roc_auc_ovr_weighted                       0.995667\nstd_train_roc_auc_ovr_weighted                        0.000064\nsplit0_test_f1_macro                                  0.915431\nsplit1_test_f1_macro                                  0.912973\nsplit2_test_f1_macro                                  0.913819\nmean_test_f1_macro                                    0.914074\nstd_test_f1_macro                                      0.00102\nrank_test_f1_macro                                           3\nsplit0_train_f1_macro                                 0.937415\nsplit1_train_f1_macro                                 0.937111\nsplit2_train_f1_macro                                 0.936881\nmean_train_f1_macro                                   0.937136\nstd_train_f1_macro                                    0.000219\nName: 3, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_index_  # only with refit for multi-scoring cases\n",
    "resultsCVDF.iloc[logreg_clf_gscv.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:11.138936Z",
     "end_time": "2023-08-25T15:09:13.804628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['7', '0', '6', ..., '5', '4', '5'], dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logreg_clf_gscv.best_estimator_)  # only with refit\n",
    "logreg_clf_gscv.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:13.802968Z",
     "end_time": "2023-08-25T15:09:13.814140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924043746498915\n",
      "{'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(logreg_clf_gscv.best_score_)  # only with refit for multi-scoring cases\n",
    "print(logreg_clf_gscv.best_params_)  # only with refit for multi-scoring cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:13.815141Z",
     "end_time": "2023-08-25T15:09:13.843141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'cv': 3,\n 'error_score': nan,\n 'estimator__C': 1.0,\n 'estimator__class_weight': None,\n 'estimator__dual': False,\n 'estimator__fit_intercept': True,\n 'estimator__intercept_scaling': 1,\n 'estimator__l1_ratio': None,\n 'estimator__max_iter': 100,\n 'estimator__multi_class': 'auto',\n 'estimator__n_jobs': None,\n 'estimator__penalty': 'l2',\n 'estimator__random_state': None,\n 'estimator__solver': 'lbfgs',\n 'estimator__tol': 0.0001,\n 'estimator__verbose': 0,\n 'estimator__warm_start': False,\n 'estimator': LogisticRegression(),\n 'n_jobs': None,\n 'param_grid': [{'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10]}],\n 'pre_dispatch': '2*n_jobs',\n 'refit': 'roc_auc_ovr_weighted',\n 'return_train_score': True,\n 'scoring': ['accuracy', 'roc_auc_ovr_weighted', 'f1_macro'],\n 'verbose': 0}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf_gscv.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:13.830143Z",
     "end_time": "2023-08-25T15:09:16.617930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['7', '0', '6', ..., '5', '4', '5'], dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf_gscv.predict(X_train)  # only when refit is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:09:16.623929Z",
     "end_time": "2023-08-25T15:12:50.723311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.91575           nan 0.91532143        nan 0.91560715]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.93799107        nan 0.93798214        nan 0.93819642]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.99239639        nan 0.99240437        nan 0.99240299]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.9956692         nan 0.99566703        nan 0.99568265]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.91451884        nan 0.91407424        nan 0.91436886]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan 0.93712965        nan 0.93713557        nan 0.937348  ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, estimator=LogisticRegression(),\n                   param_distributions=[{'C': [0.1, 1, 10],\n                                         'penalty': ['l1', 'l2']}],\n                   refit='roc_auc_ovr_weighted', return_train_score=True,\n                   scoring=['accuracy', 'roc_auc_ovr_weighted', 'f1_macro'])",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=LogisticRegression(),\n                   param_distributions=[{&#x27;C&#x27;: [0.1, 1, 10],\n                                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n                   refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n                   scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=LogisticRegression(),\n                   param_distributions=[{&#x27;C&#x27;: [0.1, 1, 10],\n                                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n                   refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n                   scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logreg_clf_rscv = RandomizedSearchCV(estimator = LogisticRegression(),\n",
    "                                     param_distributions = params,\n",
    "                                     n_iter = 10,  # num param settings sampled\n",
    "                                     random_state = None,  # if not none uses this integer as seed\n",
    "                                     scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                                     refit = \"roc_auc_ovr_weighted\",  # True\n",
    "                                     cv = 3,  # If our estimator is classifier automatically do stratified CV\n",
    "                                     # n_jobs = -1,  # Num CPUs to use for calculation, -1 means all\n",
    "                                     verbose = 0,  # Output status updates, higher number-> more messages\n",
    "                                     return_train_score = True)  # if false our results won't contain training scores\n",
    "logreg_clf_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:12:50.724311Z",
     "end_time": "2023-08-25T15:12:50.754388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_penalty  \\\n",
      "2       0.494546      0.017001         0.000000        0.000000            l1   \n",
      "4       0.509363      0.024594         0.000000        0.000000            l1   \n",
      "0       0.549329      0.054186         0.000000        0.000000            l1   \n",
      "5      14.318165      0.378823         1.986125        0.014349            l2   \n",
      "3      15.189989      0.677781         2.055560        0.035031            l2   \n",
      "1      15.372425      0.660234         2.120950        0.105380            l2   \n",
      "\n",
      "  param_C                       params  split0_test_accuracy  \\\n",
      "2       1    {'penalty': 'l1', 'C': 1}                   NaN   \n",
      "4      10   {'penalty': 'l1', 'C': 10}                   NaN   \n",
      "0     0.1  {'penalty': 'l1', 'C': 0.1}                   NaN   \n",
      "5      10   {'penalty': 'l2', 'C': 10}              0.916376   \n",
      "3       1    {'penalty': 'l2', 'C': 1}              0.916484   \n",
      "1     0.1  {'penalty': 'l2', 'C': 0.1}              0.917019   \n",
      "\n",
      "   split1_test_accuracy  split2_test_accuracy  ...  split1_test_f1_macro  \\\n",
      "2                   NaN                   NaN  ...                   NaN   \n",
      "4                   NaN                   NaN  ...                   NaN   \n",
      "0                   NaN                   NaN  ...                   NaN   \n",
      "5              0.914341              0.916104  ...              0.913050   \n",
      "3              0.914287              0.915193  ...              0.912973   \n",
      "1              0.914609              0.915622  ...              0.913319   \n",
      "\n",
      "   split2_test_f1_macro  mean_test_f1_macro  std_test_f1_macro  \\\n",
      "2                   NaN                 NaN                NaN   \n",
      "4                   NaN                 NaN                NaN   \n",
      "0                   NaN                 NaN                NaN   \n",
      "5              0.914758            0.914369           0.000958   \n",
      "3              0.913819            0.914074           0.001020   \n",
      "1              0.914265            0.914519           0.001098   \n",
      "\n",
      "   rank_test_f1_macro  split0_train_f1_macro  split1_train_f1_macro  \\\n",
      "2                   4                    NaN                    NaN   \n",
      "4                   4                    NaN                    NaN   \n",
      "0                   4                    NaN                    NaN   \n",
      "5                   2               0.937361               0.936946   \n",
      "3                   3               0.937415               0.937111   \n",
      "1                   1               0.937429               0.936461   \n",
      "\n",
      "   split2_train_f1_macro  mean_train_f1_macro  std_train_f1_macro  \n",
      "2                    NaN                  NaN                 NaN  \n",
      "4                    NaN                  NaN                 NaN  \n",
      "0                    NaN                  NaN                 NaN  \n",
      "5               0.937737             0.937348            0.000323  \n",
      "3               0.936881             0.937136            0.000219  \n",
      "1               0.937499             0.937130            0.000474  \n",
      "\n",
      "[6 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "resultsRSDF = pd.DataFrame(logreg_clf_rscv.cv_results_)\n",
    "print(resultsRSDF.sort_values(\"mean_fit_time\", ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T15:12:50.758389Z",
     "end_time": "2023-08-25T16:13:24.069717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\eequa\\Anaconda3\\envs\\ai\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{'C': [1], 'penalty': ['l1'], 'solver': ['saga']}],\n             refit='roc_auc_ovr_weighted', return_train_score=True,\n             scoring=['accuracy', 'roc_auc_ovr_weighted', 'f1_macro'])",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{&#x27;C&#x27;: [1], &#x27;penalty&#x27;: [&#x27;l1&#x27;], &#x27;solver&#x27;: [&#x27;saga&#x27;]}],\n             refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n             scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n             param_grid=[{&#x27;C&#x27;: [1], &#x27;penalty&#x27;: [&#x27;l1&#x27;], &#x27;solver&#x27;: [&#x27;saga&#x27;]}],\n             refit=&#x27;roc_auc_ovr_weighted&#x27;, return_train_score=True,\n             scoring=[&#x27;accuracy&#x27;, &#x27;roc_auc_ovr_weighted&#x27;, &#x27;f1_macro&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{\"penalty\": [\"l1\"], \"C\": [1], \"solver\": [\"saga\"]}]\n",
    "\n",
    "# params = [{\"penalty\":[\"l1\"],\"C\":[0.1,1,10],\"solver\":[\"saga\"]},\n",
    "#          {\"penalty\":[\"l2\"],\"C\":[0.1,1,10],\"solver\":[\"saga\"]},\n",
    "#          {\"penalty\":[\"l2\"],\"C\":[0.1,1,10],\"solver\":[\"lbfgs\"]}]\n",
    "\n",
    "logreg_clf_gscv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                               param_grid = params,\n",
    "                               scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                               refit = \"roc_auc_ovr_weighted\",  # True\n",
    "                               cv = 3,  # If our estimator is classifier automatically do stratified CV\n",
    "                               # n_jobs=-1,  # Num CPUs to use for calculation, -1 means all\n",
    "                               verbose = 0,  # Output status updates, higher number-> more messages\n",
    "                               return_train_score = True)  # if false our results won't contain training scores\n",
    "logreg_clf_gscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T16:13:24.160416Z",
     "end_time": "2023-08-25T16:13:24.226584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time                                                         814.245986\n",
      "std_fit_time                                                           16.406915\n",
      "mean_score_time                                                         2.034508\n",
      "std_score_time                                                          0.036846\n",
      "param_C                                                                        1\n",
      "param_penalty                                                                 l1\n",
      "param_solver                                                                saga\n",
      "params                               {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "split0_test_accuracy                                                    0.916644\n",
      "split1_test_accuracy                                                    0.914127\n",
      "split2_test_accuracy                                                    0.915729\n",
      "mean_test_accuracy                                                        0.9155\n",
      "std_test_accuracy                                                       0.001041\n",
      "rank_test_accuracy                                                             1\n",
      "split0_train_accuracy                                                   0.943133\n",
      "split1_train_accuracy                                                   0.942464\n",
      "split2_train_accuracy                                                   0.942331\n",
      "mean_train_accuracy                                                     0.942643\n",
      "std_train_accuracy                                                      0.000351\n",
      "split0_test_roc_auc_ovr_weighted                                        0.992377\n",
      "split1_test_roc_auc_ovr_weighted                                        0.992381\n",
      "split2_test_roc_auc_ovr_weighted                                        0.992724\n",
      "mean_test_roc_auc_ovr_weighted                                          0.992494\n",
      "std_test_roc_auc_ovr_weighted                                           0.000163\n",
      "rank_test_roc_auc_ovr_weighted                                                 1\n",
      "split0_train_roc_auc_ovr_weighted                                       0.996365\n",
      "split1_train_roc_auc_ovr_weighted                                       0.996344\n",
      "split2_train_roc_auc_ovr_weighted                                       0.996175\n",
      "mean_train_roc_auc_ovr_weighted                                         0.996295\n",
      "std_train_roc_auc_ovr_weighted                                          0.000085\n",
      "split0_test_f1_macro                                                    0.915503\n",
      "split1_test_f1_macro                                                    0.912852\n",
      "split2_test_f1_macro                                                    0.914406\n",
      "mean_test_f1_macro                                                      0.914254\n",
      "std_test_f1_macro                                                       0.001087\n",
      "rank_test_f1_macro                                                             1\n",
      "split0_train_f1_macro                                                   0.942337\n",
      "split1_train_f1_macro                                                   0.941729\n",
      "split2_train_f1_macro                                                   0.941544\n",
      "mean_train_f1_macro                                                      0.94187\n",
      "std_train_f1_macro                                                      0.000339\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(logreg_clf_gscv.cv_results_).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-25T16:13:24.228583Z",
     "end_time": "2023-08-25T16:13:24.234583Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
